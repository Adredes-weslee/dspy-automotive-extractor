# Langfuse Credentials - Get these from your Langfuse project settings
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_HOST="http://localhost:3000"

# Ollama Model Configuration
# For high-performance GPUs (>= 8GB VRAM), use "gemma3:12b"
# For CPU-only or lower-end GPUs, use "qwen3:4b"
OLLAMA_MODEL="gemma3:12b"